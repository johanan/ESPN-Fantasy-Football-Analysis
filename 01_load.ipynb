{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Games and Teams\n",
    "This will load all the games and teams and process them ready to be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "load_dotenv()\n",
    "league_id = os.getenv('league_id')\n",
    "current_year = int(os.getenv('current_year'))\n",
    "url = \"https://fantasy.espn.com/apis/v3/games/ffl/seasons/{}/segments/0/leagues/{}\".format(current_year, league_id)\n",
    "history_url = \"https://fantasy.espn.com/apis/v3/games/ffl/leagueHistory/{}\".format(league_id)\n",
    "cookies = {\n",
    "        \"swid\": os.getenv('swid'),\n",
    "        \"espn_s2\": os.getenv('espn_s2')\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load All the Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for games\n",
    "def add_year(game, season_id):\n",
    "    game[\"year\"] = season_id\n",
    "    return game\n",
    "\n",
    "def get_schedule(season_id):\n",
    "    hist_req = requests.get(history_url,\n",
    "        cookies=cookies,\n",
    "        params={\"view\": \"mMatchup\", \"seasonId\": season_id,})\n",
    "    hist_list = list(map(lambda x: add_year(x, season_id), hist_req.json()[0][\"schedule\"]))\n",
    "    return hist_list\n",
    "    \n",
    "games_req = requests.get(url,\n",
    "params={\"view\": \"mMatchup\"},\n",
    "    cookies=cookies)\n",
    "schedule = list(map(lambda x: add_year(x, current_year), games_req.json()[\"schedule\"]))\n",
    "\n",
    "# load all the previous seasons from the response\n",
    "prev = games_req.json()[\"status\"][\"previousSeasons\"]\n",
    "# builds the full schedule for each year\n",
    "prev_games = list(map(get_schedule, prev))\n",
    "\n",
    "# flatten all the historical games to the current list of games\n",
    "all_games = schedule + reduce(list.__add__, prev_games)\n",
    "\n",
    "# process everything to just the weeks, teams, scores\n",
    "games_df = pd.DataFrame([[game[\"matchupPeriodId\"], \n",
    "game[\"home\"][\"teamId\"], game[\"home\"][\"totalPoints\"],\n",
    "game[\"away\"][\"teamId\"], game[\"away\"][\"totalPoints\"], game[\"year\"]] for game in all_games],\n",
    "    columns=['Week', 'Team1', 'Score1', 'Team2', 'Score2', \"year\"])\n",
    "\n",
    "# calculate win margins\n",
    "game_margin_df = games_df.assign(Margin1 = games_df[\"Score1\"] - games_df[\"Score2\"],\n",
    "    Margin2 = games_df[\"Score2\"] - games_df[\"Score1\"])\n",
    "\n",
    "# rename and save\n",
    "g_flattened = (game_margin_df[['Week', 'Team1', 'Margin1', 'Score1', 'Score2', 'year']]\n",
    "    .rename(columns={'Team1': 'Team', 'Score1': 'Score', 'Margin1': 'Margin', 'Score2': 'OppScore'})\n",
    "    .append(game_margin_df[['Week', 'Team2', 'Margin2', 'Score2', 'Score1', 'year']]\n",
    "    .rename(columns={'Team2': 'Team', 'Score2': 'Score', 'Margin2': 'Margin', 'Score1': 'OppScore'})\n",
    "    ))\n",
    "\n",
    "# get the mean for each week\n",
    "def add_week_avg(grp):\n",
    "    grp[\"week_mean\"] = grp[\"Score\"].mean()\n",
    "    return grp\n",
    "\n",
    "# apply the mean\n",
    "g_flattened = g_flattened.groupby([\"year\", \"Week\"]).apply(add_week_avg)\n",
    "\n",
    "# add wins and diff from mean\n",
    "g_flattened[\"win\"] = g_flattened[\"Margin\"] > 0\n",
    "g_flattened[\"for_diff\"] = g_flattened[\"Score\"] - g_flattened[\"week_mean\"]\n",
    "g_flattened[\"against_diff\"] = g_flattened[\"OppScore\"] - g_flattened[\"week_mean\"]\n",
    "\n",
    "# calculate unlucky and lucky\n",
    "g_flattened[\"unlucky_loss\"] = 0\n",
    "g_flattened[\"lucky_win\"] = 0\n",
    "g_flattened.loc[(g_flattened[\"win\"] == False) & (g_flattened[\"for_diff\"] > 0), \"unlucky_loss\"] = 1\n",
    "g_flattened.loc[(g_flattened[\"win\"] == True) & (g_flattened[\"for_diff\"] < 0), \"lucky_win\"] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load All the Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for teams\n",
    "def get_data(args):\n",
    "    season_id, load_url = args\n",
    "    team_req = requests.get(load_url,\n",
    "        cookies=cookies,\n",
    "        params={\"seasonId\": season_id, \"view\": \"mTeam\"})\n",
    "    teams = team_req.json()[0][\"teams\"]\n",
    "    teams_df = pd.DataFrame(pd.json_normalize(teams))\n",
    "    teams_df[\"year\"] = season_id\n",
    "    return teams_df\n",
    "    \n",
    "current_teams_req = requests.get(url,\n",
    "    cookies=cookies,\n",
    "    params={\"view\": \"mTeam\"})\n",
    "curr_teams = current_teams_req.json()[\"teams\"]\n",
    "year = current_teams_req.json()[\"seasonId\"]\n",
    "full_teams_df = pd.DataFrame(pd.json_normalize(curr_teams))\n",
    "full_teams_df[\"year\"] = year\n",
    "\n",
    "# build the call to load all the previous teams\n",
    "mapped_hist_teams = map(get_data, list(map(lambda y: (y, history_url), prev)))\n",
    "full_teams_df = full_teams_df.append(pd.concat(list(mapped_hist_teams)))\n",
    "\n",
    "# scale the data to compare between years\n",
    "scaler = StandardScaler()\n",
    "def zscore(group):\n",
    "    scaled = scaler.fit_transform(X=group[[\"record.overall.pointsFor\", \"record.overall.pointsAgainst\", 'transactionCounter.moveToActive']])\n",
    "    group[\"scaled_pointsFor\"], group[\"scaled_pointsAgainst\"], group[\"scaled_moves\"] = scaled[:,0], scaled[:,1], scaled[:,2]\n",
    "    return group\n",
    "\n",
    "full_scaled_df = full_teams_df.groupby(\"year\").apply(zscore)\n",
    "\n",
    "# logic to determin in the money (itm) or last place\n",
    "def calc_itm_last(group):\n",
    "    group.loc[group[\"rankCalculatedFinal\"] <= 3, 'itm'] = 1\n",
    "    group.loc[group[\"rankCalculatedFinal\"] > 3, 'itm'] = 0\n",
    "    group.loc[group[\"rankCalculatedFinal\"] == 0, 'itm'] = np.nan\n",
    "    group.loc[(group[\"rankCalculatedFinal\"] == group[\"rankCalculatedFinal\"].max()) & (group[\"rankCalculatedFinal\"] != 0), 'last_place'] = 1\n",
    "    group.loc[group[\"last_place\"] != 1, 'last_place'] = 0\n",
    "    return group\n",
    "\n",
    "itm_teams = full_scaled_df.groupby(\"year\").apply(calc_itm_last)\n",
    "\n",
    "itm_teams.to_csv(\"processed_teams.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the Team Abbreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrev = itm_teams[['abbrev', 'year', 'id']]\n",
    "games_abbrev = g_flattened.merge(abbrev, left_on=['year', 'Team'], right_on=['year', 'id'])\n",
    "games_abbrev.to_csv(\"processed_games.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "39c2ff9da26a0b1bf6a0df58ab90869e557499b226f710ff7b3d721ffc703b6d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
